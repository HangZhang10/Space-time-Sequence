# 7.常用数据处理及评估

对于序列问题，针对数据的输入、输出格式可以分为如下几大类问题，可以应用于不同的领域。序列问题不同于普通的分类问题，其输入、输出的特征和标签需要进行特殊的处理，而时间序列预测问题的输入、输出和其它序列问题也存在一些差别，本章针对时间序列常用的数据处理方法进行了讲解。
<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/63.png"/></div>

## 7.1 特征和标签划分
 
 监督学习往往需要针对样本数据进行特征和标签的划分，对于单维、多维时间序列以及时序图，其划分的方法都比较类似，具体可以分析如下几种情况：

- one to one 

不论是单维、多维还是时序图，都是把t时刻的数据作为特征，t+1的数据作为标签，随着t从序列头部到后部不断移动，由此构造出序列的特征和标签。<br>

- one to many:

不论是单维、多维还是时序图，都是把t时刻的数据作为特征，t+K的数据作为标签，随着t从序列头部到后部不断移动，由此构造出序列的特征和标签。<br>

- many to one:

不论是单维、多维还是时序图，都是把t-k时刻的数据作为特征，t时刻的数据作为标签，随着t从序列头部到后部不断移动，由此构造出序列的特征和标签。<br>

- many to many:

不论是单维、多维还是时序图，都是把t-k时刻的数据作为特征，t+K的数据作为标签，随着t从序列头部到后部不断移动，由此构造出序列的特征和标签。<br>

**【举个例子】**<br>

1、对于多维/单维时间序列（以单维为例）：
假设存在序列数据 data = [1, 2, 3, 4, 5, 6, 7, 8] <br>
- one to one

当k=1时，特征X=[[1], [2], [3], [4], [5], [6], [7]] <br>
对应的标签Y=[[2], [3], [4], [5], [6], [7], [8]]<br>

- many to one

当k=2时，特征X=[[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]] <br>
对应的标签Y=[[3], [4], [5], [6], [7], [8]] <br>

- many to many

当k=2时，特征X=[[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]]<br>
对应的标签Y=[[3, 4], [4, 5], [5, 6], [6, 7], [7, 8]]<br>

- one to many

当k=2时，特征X=[[1], [2], [3], [4], [5], [6]]<br>
对应的标签Y=[[2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8]]<br>

2、对于时序网络图：
假设存在时序图网络序列 data = [g1, g2, g3, g4, g5, g6, g7, g8],其中g1,g2...g8分别是在时刻1，时刻2...时刻8构成的静态图。<br>

- one to one

当k=1时，特征X=[[g1], [g2], [g3], [g4], [g5], [g6], [g7]]<br>
对应的标签Y=[[g2], [g3], [g4], [g5], [g6], [g7], [g8]]<br>

- many to one

当k=2时，特征X=[[g1, g2], [g2, g3], [g3, g4], [g4, g5], [g5, g6], [g6, g7]]<br>
对应的标签Y=[[g3], [g4], [g5], [g6], [g7], [g8]]<br>

对于其它几种情况也是类似的处理，具体可以参考如下的两个函数代码：<br>

```
def createSamples(ts, lookBack, lookAhead):
    dataX, dataY = [], []
    for i in range(len(ts) - lookBack - lookAhead):
        history_seq = ts[i: i + lookBack]
        future_seq = ts[i + lookBack: i + lookBack + lookAhead]
        dataX.append(history_seq)
        dataY.append(future_seq)
    dataX = np.array(dataX)
    dataY = np.array(dataY)
    return dataX, dataY
    
def generate_networkx_graphs(glist, batch_size):
    index = range(len(glist)-2)
    input_index = random.sample(index, batch_size)
    target_index = [ ix+1 for ix in input_index ]
    input_graph = [glist[k] for k in input_index]
    target_graph = [glist[k] for k in target_index]
    input_graphs = [graph_to_input_target(graph) for graph in input_graph]
    target_graphs = [graph_to_input_target(graph) for graph in target_graph]
    
    return input_graphs, target_graphs
```

## 7.2 预测逐步向后推进

预测逐步向后推进：是指每次只预测一个值，获得该预测值后，把该值加入测试集中去预测下一个值，一般来说无需重新训练模型。举个简单的案例，用SVR做单维时间序列的回归时，我们可以把每次预测到的几个值，加入后续的预测历史数据中，如下代码：

```
def predict_SVR_iteration(testX, lookAhead, svrModel):
    testBatchSize = testX.shape[0]
    ans = []

    for i in range(lookAhead):

        pred = svrModel.predict(testX)  # (test_num, )
        ans.append(pred)

        testX = testX[:, 1:]
        pred = pred.reshape((testBatchSize, 1))
        testX = np.append(testX, pred, axis=1)

    ans = np.array(ans)
    ans = ans.transpose([1, 0])
    return ans
```

## 7.3 数据评估

对于时间序列预测，常用的评估指标如下几个：<br>

- 平均绝对误差 MAE
是基础的评估方法，后面的方法一般以此为参考对比优劣。
<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/75.png"/></div>

- 均方误差 MSE
对比MAE，MSE可以放大预测偏差较大的值，可以比较不同预测模型的稳定性，应用场景相对多一点。
<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/76.png"/></div>

- 均方根误差 RMSE
 因为使用的是平均误差，而平均误差对异常点较敏感，如果回归器对某个点的回归值很不合理，那么它的误差则比较大，从而会对RMSE的值有较大影响，即平均值是非鲁棒的。<br>
 改进：使用误差的分位数来代替，如中位数来代替平均数。假设100个数，最大的数再怎么改变，中位数也不会变，因此其对异常点具有鲁棒性。<br>
 平均平方差/均方误差是回归任务最常用的性能度量。<br>
<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/77.png"/></div>

- 平均百分误差 MAPE
<div align=center><img src="https://github.com/xchadesi/st_graph_book/blob/master/docs/images/78.PNG"/></div>
MAPE不仅仅考虑预测值与真实值的误差，还考虑了误差与真实值之间的比例，在某些场景下，比如房价从0.5w到5w之间，0.5预测成1.0与5.0预测成4.5的差距是非常大的，在一些竞赛当中，MAPE也是常用的目标函数之一。在统计领域是一个预测准确性的衡量指标。

```
from sklearn.metrics import mean_squared_error #均方误差
from sklearn.metrics import mean_absolute_error #平方绝对误差

#MAPE
import numpy as np
def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100
```
